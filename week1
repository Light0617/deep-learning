1.
when choosing how much data to give to a learning system in order to make it generalize well, we need to make sure that we don't give it too much data.
false

2.
Data can change over time, in particular we might observe different input/output relationships. In order to account for this we can adapt our learning system to the new data by, for example, training on new examples.
If the relationship between inputs and outputs for old examples has not changed, how can we prevent a neural network from forgetting about the old data?

Train on a mix of old and new data.
Prevent the system from changing the weights too much.

3.
Which of the following are good reasons for why we are interested in unsupervised learning?
It allows us to learn from vast amounts of unlabelled data.
It can be used to learn features that may help with supervised tasks.

4.
Which of the following tasks are neural networks good at?
Recognizing fragments of words in a pre-processed sound wave.
Recognizing badly written characters.

5.
Which number is biggest?
The number of synapes in a human brain.

6.
Which of the following facts provides support for the theory that the local neural circuits in most parts of the cortex all use the same general purpose learning algorithm?
The fine-scale anatomy of the cortex looks pretty much the same all over.
If the visual input is sent to the auditory cortex of a newborn ferret, the "auditory" cells learn to do vision.
If part of the cortex is removed early in life, the function that it would have served often gets relocated to another part of cortex.



